/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/utils/dl_utils/setup_env.py:56: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/utils/dl_utils/setup_env.py:56: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
Traceback (most recent call last):
  File "tools/train.py", line 161, in <module>
Traceback (most recent call last):
  File "tools/train.py", line 161, in <module>
    main()
      File "tools/train.py", line 157, in main
main()
  File "tools/train.py", line 157, in main
    runner.train()
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1745, in train
    runner.train()
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/runner.py", line 1745, in train
        model = self.train_loop.run()  # type: ignoremodel = self.train_loop.run()  # type: ignore

  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 96, in run
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 96, in run
        self.run_epoch()self.run_epoch()

  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 112, in run_epoch
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 112, in run_epoch
    self.run_iter(idx, data_batch)    
self.run_iter(idx, data_batch)  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 128, in run_iter

  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/runner/loops.py", line 128, in run_iter
    outputs = self.runner.model.train_step(
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/model/wrappers/distributed.py", line 121, in train_step
    outputs = self.runner.model.train_step(
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/model/wrappers/distributed.py", line 121, in train_step
    losses = self._run_forward(data, mode='loss')
      File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/model/wrappers/distributed.py", line 161, in _run_forward
losses = self._run_forward(data, mode='loss')
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/model/wrappers/distributed.py", line 161, in _run_forward
    results = self(**data, mode=mode)
      File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
results = self(**data, mode=mode)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
        return forward_call(*input, **kwargs)return forward_call(*input, **kwargs)

  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 947, in forward
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 947, in forward
        if torch.is_grad_enabled() and self.reducer._rebuild_buckets():if torch.is_grad_enabled() and self.reducer._rebuild_buckets():

RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
making sure all `forward` function outputs participate in calculating loss. 
If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
Parameter indices which did not receive grad for rank 1: 39 40 41 42
 In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this errorRuntimeError
: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
making sure all `forward` function outputs participate in calculating loss. 
If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
Parameter indices which did not receive grad for rank 0: 39 40 41 42
 In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22178 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 22179) of binary: /home/nr4325/miniconda3/envs/pose4/bin/python
Traceback (most recent call last):
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
tools/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-28_17:23:13
  host      : skl-a-48.rc.rit.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 22179)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
