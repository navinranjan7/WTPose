/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/attention.py:471: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x = x.view(B, H // window_size, window_size, W // window_size,
/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/attention.py:298: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  C // self.num_heads).permute(2, 0, 3, 1, 4)
/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/attention.py:463: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  x = windows.view(B, H // window_size, W // window_size, window_size,
/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/attention.py:323: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  attn = attn.view(B_ // nW, nW, self.num_heads, N,
/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/embed.py:405: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  out_h = (H + 2 * self.sampler.padding[0] - self.sampler.dilation[0] *
/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/embed.py:408: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  out_w = (W + 2 * self.sampler.padding[1] - self.sampler.dilation[1] *
Traceback (most recent call last):
  File "tools/analysis_tools/get_flops.py", line 142, in <module>
    main()
  File "tools/analysis_tools/get_flops.py", line 126, in main
    outputs = inference(args, input_shape, logger)
  File "tools/analysis_tools/get_flops.py", line 102, in inference
    outputs = get_model_complexity_info(
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/analysis/print_helper.py", line 748, in get_model_complexity_info
    flops = flop_handler.total()
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/analysis/jit_analysis.py", line 268, in total
    stats = self._analyze()
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/analysis/jit_analysis.py", line 570, in _analyze
    graph = _get_scoped_trace_graph(self._model, self._inputs,
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/mmengine/analysis/jit_analysis.py", line 194, in _get_scoped_trace_graph
    graph, _ = _get_trace_graph(module, inputs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/jit/_trace.py", line 1166, in _get_trace_graph
    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/jit/_trace.py", line 127, in forward
    graph, out = torch._C._create_graph_by_tracing(
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/jit/_trace.py", line 118, in wrapper
    outs.append(self.inner(*trace_inputs))
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1098, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/pose_estimators/base.py", line 172, in _forward
    x = self.extract_feat(inputs)
  File "/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/pose_estimators/base.py", line 188, in extract_feat
    x = self.backbone(inputs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1098, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/backbones/wt_swinv2.py", line 856, in forward
    x = self.wtm(outs, resnet_out)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/nr4325/miniconda3/envs/pose4/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1098, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/home/nr4325/Desktop/Pose4/mmpose/mmpose/models/utils/wtm_a.py", line 158, in forward
    x = torch.cat([inputs[0], inputs1, inputs2, inputs3], dim=1)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 72 but got size 96 for tensor number 1 in the list.
